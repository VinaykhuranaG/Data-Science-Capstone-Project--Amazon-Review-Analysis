{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255973c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ea4c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn import svm\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccbb7c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>7584</td>\n",
       "      <td>7436</td>\n",
       "      <td>poor qualityone star</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>10025</td>\n",
       "      <td>6869</td>\n",
       "      <td>goodfive star</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>51333</td>\n",
       "      <td>47813</td>\n",
       "      <td>love itfive star</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Review                                  \n",
       "           count unique                   top freq\n",
       "Sentiment                                         \n",
       "Negative    7584   7436  poor qualityone star    4\n",
       "Neutral    10025   6869         goodfive star  402\n",
       "Positive   51333  47813      love itfive star  437"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beauty=pd.read_csv('beauty_cleandata11.csv')#read data\n",
    "beauty.drop('Unnamed: 0',axis=1,inplace=True)# drop unnamed column\n",
    "beauty2 = beauty[[\"Sentiment\",\"Review\"]]\n",
    "beauty2.groupby('Sentiment').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef7a89f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin            0\n",
       "title           0\n",
       "overall         0\n",
       "brand           0\n",
       "rank            0\n",
       "verified        0\n",
       "reviewerID      0\n",
       "reviewerName    3\n",
       "reviewTime      0\n",
       "price           0\n",
       "style           0\n",
       "also_buy        0\n",
       "also_view       0\n",
       "main_cat        0\n",
       "Review          1\n",
       "polarity        0\n",
       "Sentiment       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beauty.isnull().sum() #check null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b3104d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "beauty.dropna(inplace=True)#drop null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fe372d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (51704,)\n",
      "y_train shape: (51704,)\n",
      "\n",
      "x_test shape: (17235,)\n",
      "y_test shape: (17235,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "x_train, x_test, y_train, y_test = train_test_split(beauty['Review'], beauty['Sentiment'], random_state=42)\n",
    "print(\"x_train shape: {}\".format(x_train.shape), end='\\n')\n",
    "print(\"y_train shape: {}\".format(y_train.shape), end='\\n\\n')\n",
    "print(\"x_test shape: {}\".format(x_test.shape), end='\\n')\n",
    "print(\"y_test shape: {}\".format(y_test.shape), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feabf5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acf5a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7953cab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Fitting and transforming the training data to a document-term matrix using TfidfVectorizer \n",
    "# Vectorize X_train\n",
    "vectorizer = CountVectorizer(min_df=5).fit(x_train)\n",
    "X_train = vectorizer.transform(x_train)\n",
    "X_test = vectorizer.transform(x_test)\n",
    "# Logistic Regression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "# Evaluate the model on validaton set\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb16e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ab3d1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and vectorizer using joblib\n",
    "joblib.dump(vectorizer, 'vectorizer.joblib')\n",
    "joblib.dump(classifier, 'classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d875e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f82ba46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16ad61a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'machine learning in big data analytics-1.webp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvectorizer.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Load and resize image\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmachine learning in big data analytics-1.webp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m1360\u001b[39m, \u001b[38;5;241m768\u001b[39m), Image\u001b[38;5;241m.\u001b[39mANTIALIAS)\n\u001b[0;32m     30\u001b[0m img_tk \u001b[38;5;241m=\u001b[39m ImageTk\u001b[38;5;241m.\u001b[39mPhotoImage(img)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py:2953\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2950\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   2952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 2953\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2954\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2956\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'machine learning in big data analytics-1.webp'"
     ]
    }
   ],
   "source": [
    "from tkinter import ttk\n",
    "from tkinter import *\n",
    "from PIL import Image, ImageTk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import threading\n",
    "\n",
    "def classify_text():\n",
    "    text = text_box.get(\"1.0\", \"end\").strip()\n",
    "    if not text:\n",
    "        result_label.configure(text=\"Please enter some text.\")\n",
    "        return\n",
    "    text_features = vectorizer.transform([text])\n",
    "    prediction = classifier.predict(text_features)[0]\n",
    "    result_label.configure(text=f\"Prediction: {prediction}\")\n",
    "\n",
    "def classify_text_threaded():\n",
    "    # Create a new thread for the analysis function\n",
    "    t = threading.Thread(target=classify_text)\n",
    "    t.start()\n",
    "\n",
    "root = Tk()\n",
    "root.title(\"NLP Analysis\")\n",
    "\n",
    "# Load classification model\n",
    "classifier = joblib.load(\"classifier.joblib\")\n",
    "vectorizer = joblib.load(\"vectorizer.joblib\")\n",
    "# Load and resize image\n",
    "img = Image.open(\"machine learning in big data analytics-1.webp\")\n",
    "img = img.resize((1360, 768), Image.ANTIALIAS)\n",
    "img_tk = ImageTk.PhotoImage(img)\n",
    "\n",
    "# Set background image\n",
    "background_label = Label(root, image=img_tk)\n",
    "background_label.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "\n",
    "# Create Text widget\n",
    "text_box = Text(root, height=10, width=50, wrap=\"word\", font=(\"Arial\", 12), highlightbackground=\"#D0D0D0\", highlightthickness=1,bg=\"#F0F0F0\", bd=1,relief=\"solid\", fg=\"red\")\n",
    "text_box.insert(END, \"Enter text here...\")\n",
    "text_box.grid(row=0, column=0, padx=20, pady=20, sticky=\"w\"+\"e\"+\"n\"+\"s\")\n",
    "# Create Analysis button with custom style\n",
    "style = ttk.Style()\n",
    "style.configure(\"Custom.TButton\", font=(\"Arial\", 14), background=\"green\", foreground=\"black\")\n",
    "sentiment_button = ttk.Button(root, text=\"Analyze Sentiment\", command=classify_text_threaded, style=\"Custom.TButton\", width=20)\n",
    "sentiment_button.grid(row=0, column=1, padx=20, pady=20)\n",
    "\n",
    "# Create label to display results\n",
    "result_label = ttk.Label(root, text=\"\", font=(\"Arial\", 14))\n",
    "result_label.grid(row=1, column=0, columnspan=2, padx=20, pady=20)\n",
    "\n",
    "# Set focus to Text widget and move cursor to beginning\n",
    "text_box.focus_set()\n",
    "text_box.tag_add(\"start\", \"1.0\", \"1.0\")\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e927a3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8611d4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cde2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
